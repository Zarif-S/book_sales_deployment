# Initialize the scaler
scaler_alchemist = MinMaxScaler(feature_range=(0, 1))

# Fit the scaler on the SARIMA residuals from the training data
result_sarima_df_alchemist['SARIMA Residuals_scaled'] = scaler_alchemist.fit_transform(result_sarima_df_alchemist[['SARIMA Residuals']].values)

# Transform (not fit) the SARIMA test forecast using the same scaler (use .values to avoid feature name mismatch)
result_sarima_df_alchemist['SARIMA Test_Forecast_Scaled'] = scaler_alchemist.transform(result_sarima_df_alchemist[['SARIMA Test_Forecast']].values)

# Inverse transform the predictions
train_best_predict = scaler_alchemist.inverse_transform(train_best_predict)
test_best_predict = scaler_alchemist.inverse_transform(test_best_predict)

Y_best_test = scaler_alchemist.inverse_transform(Y_test.reshape(-1, 1)).flatten()

train_best_predict_flat = train_best_predict.flatten()
test_best_predict_flat = test_best_predict.flatten()

final_forecast = predicted_mean_SARIMA_alchemist.values + test_best_predict_flat

# Calculate the mean squared error on the test set.
mse = mean_squared_error(result_sarima_df_alchemist['SARIMA Test_Forecast'][-32:], final_forecast)



# Define your lookback and forecast values
lookback = 12  # Use the last 12 observations
forecast = 32  # Predict the next 32 observations

# Define the cut-off point (655-32)
cutoff = len(result_sarima_df_alchemist) - forecast

# Create combined_data where the first 655-32 rows come from 'SARIMA Residuals_scaled'
# and the last 32 rows come from 'SARIMA Test_Forecast_Scaled'
combined_data = pd.concat([
    result_sarima_df_alchemist['SARIMA Residuals_scaled'][:cutoff],  # First part
    result_sarima_df_alchemist['SARIMA Test_Forecast_Scaled'][cutoff:]  # Last part
]) #this is overcomplicated but it will work

# Create input-output sequences for the combined data
combined_sequences = create_input_sequences(lookback, forecast, combined_data.values)

# Separate the input and output sequences
X_combined = np.array(combined_sequences["input_sequences"])
Y_combined = np.array(combined_sequences["output_sequences"])

# Reshape the input sequences for LSTM [samples, time steps, features]
X_combined = X_combined.reshape(X_combined.shape[0], X_combined.shape[1], 1)

# Split back into train and test sets based on the dates
train_length = len(train_data_alchemist) - lookback  # Consider the lookback length to avoid overlap

# Split the sequences
X_train, X_test = X_combined[:train_length], X_combined[train_length:]
Y_train, Y_test = Y_combined[:train_length], Y_combined[train_length:]



print(pd.DataFrame({'Original Data': test_data_alchemist["Volume"],'Hybrid SARIMA + LSTM': final_forecast, 'SARIMA': predicted_mean_SARIMA_alchemist, 'LSTM': test_best_predict_flat}))

"""
            Original Data  Hybrid SARIMA + LSTM       SARIMA       LSTM
2023-12-16           1260           1142.593660  1155.762378 -13.168717
2023-12-23           2201           1312.082028  1325.160106 -13.078078
2023-12-30           1050            672.294696   696.247989 -23.953293
2024-01-06            806            663.956358   684.299891 -20.343533
2024-01-13            748            683.964565   702.724282 -18.759718
2024-01-20            695            598.248964   613.516960 -15.267996
2024-01-27            724            600.569533   618.128068 -17.558535
2024-02-03            664            617.433794   627.366976  -9.933183
"""
